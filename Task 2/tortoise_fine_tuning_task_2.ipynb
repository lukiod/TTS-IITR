{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30664,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/drive/1iqnIq_-7zbwAnu77GuiUUk3YLoJPypTr?usp=sharing\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "FZjlv16OKw3V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Downloading a high-quality TTS dataset for German language (LibriTTS-style dataset)"
      ],
      "metadata": {
        "id": "--ewOjx2wqnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# HUI-Audio-Corpus-German: A high quality TTS dataset (https://arxiv.org/pdf/2106.06309.pdf)\n",
        "!wget https://opendata.iisys.de/opendata/Datasets/HUI-Audio-Corpus-German/dataset_clean/others_Clean.zip"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "15uTrv0_wqn1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "679925b8-080b-4ef6-9d35-6c3d010f364c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-10-27 13:27:21--  https://opendata.iisys.de/opendata/Datasets/HUI-Audio-Corpus-German/dataset_clean/others_Clean.zip\n",
            "Resolving opendata.iisys.de (opendata.iisys.de)... 194.95.60.121\n",
            "Connecting to opendata.iisys.de (opendata.iisys.de)|194.95.60.121|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15937839738 (15G) [application/zip]\n",
            "Saving to: ‘others_Clean.zip’\n",
            "\n",
            "others_Clean.zip      0%[                    ] 139.79M  1.12MB/s    eta 3h 50m ^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Unzip dataset"
      ],
      "metadata": {
        "id": "8jXNySIXwqn2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip ./others_Clean.zip -d ./dataset"
      ],
      "metadata": {
        "id": "bAEp8Nojwqn3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97b2b034-e3b4-4f98-956f-7a6ff21f3852"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  ./others_Clean.zip\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of ./others_Clean.zip or\n",
            "        ./others_Clean.zip.zip, and cannot find ./others_Clean.zip.ZIP, period.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adjust dataset structure so that all train and val wav files are located in an individual folder"
      ],
      "metadata": {
        "id": "TKKhd4UDwqn3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "import csv\n",
        "\n",
        "transcribed_audio_samples = []\n",
        "\n",
        "for folder in glob(\"others_dataset/*\"):\n",
        "  for subfolder in glob(f\"{folder}/*\"):\n",
        "    with open(f\"{subfolder}/metadata.csv\") as csv_file:\n",
        "        audio_samples = csv.reader(csv_file, delimiter='\\n')\n",
        "        for audio_sample in audio_samples:\n",
        "            transcribed_audio_sample = ''.join(audio_sample)\n",
        "            filename, transcription = transcribed_audio_sample.split('|')\n",
        "            new_transcribed_audio_sample = f\"wavs/{filename}.wav|{transcription}\"\n",
        "            transcribed_audio_samples.append((f\"{subfolder}/wavs/{filename}.wav\", new_transcribed_audio_sample))"
      ],
      "metadata": {
        "id": "qV-fod-awqn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Divide dataset into train and val subsets"
      ],
      "metadata": {
        "id": "VjdHbeAlwqn3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "random.shuffle(all_transcribed_audio_samples)\n",
        "num_train_samples = int(len(all_transcribed_audio_samples) * 0.85)\n",
        "\n",
        "train_dataset = transcribed_audio_samples[:num_train_samples]\n",
        "val_dataset = transcribed_audio_samples[num_train_samples:]"
      ],
      "metadata": {
        "id": "UWyNZCR4wqn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Copy files to train and val folders"
      ],
      "metadata": {
        "id": "87BT5Qqawqn4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir dataset\n",
        "!mkdir dataset/wavs"
      ],
      "metadata": {
        "id": "DGpyDlIrwqn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "train_val_list = [('train', train_dataset), ('val', val_dataset)]\n",
        "\n",
        "for stage, dataset in train_val_list:\n",
        "    sample_list = []\n",
        "    for old_sample, new_sample in dataset:\n",
        "        # copy audio sample to new location\n",
        "        shutil.copyfile(old_sample, \"./dataset/\" + new_sample.split(\"|\")[0])\n",
        "        sample_list.append(new_sample)\n",
        "\n",
        "    with open(f\"./dataset/{stage}.txt\", \"w\") as sample_file:\n",
        "        sample_file.write(\"\\n\".join(sample_list))"
      ],
      "metadata": {
        "id": "Q_eJ1R7pwqn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Zip altered dataset"
      ],
      "metadata": {
        "id": "HTEn1SQtwqn4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r hui_audio_corpus.zip ./dataset"
      ],
      "metadata": {
        "id": "-q9UxgEzwqn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Alter fine-tuning code to allow special letters (e.g. ä,ö,ü,ß for German language)\n",
        "---\n",
        "##### Source: https://github.com/152334H/DL-Art-School\n",
        "##### File: codes/models/audio/tts/tacotron2/text/cleaners.py\n",
        "- Alter method english_cleaners to clean input text for your language (line 83)\n",
        "\n",
        "##### File: codes/models/audio/tts/tacotron2/text/symbols.py\n",
        "- Add special characters to \\_letters (line 12)\n",
        "\n",
        "##### Create File: experiments/custom_language_gpt.yml\n",
        "- Copy file experiments/EXAMPLE_gpt.yml and rename it to custom_language_gpt.yml\n",
        "- Change experiment name to custom_language_gpt (line 1)\n",
        "- Change name to train_dataset (line 14)\n",
        "- Change path to ../../dataset/train.txt (line 18)\n",
        "- Add attribute *tokenizer_vocab: ../custom_language_tokenizer.json* (line 29)\n",
        "- Change name to val_dataset (line 31)\n",
        "- Change path to ../../dataset/val.txt (line 35)\n",
        "- Add attribute *tokenizer_vocab: ../custom_language_tokenizer.json* (line 46)\n",
        "- Change value to 5000 (line 128)\n",
        "\n",
        "##### File: .gitignore\n",
        "- Add statement *!experiments/custom_language_gpt.yml* (line 169)\n",
        "\n",
        "##### File: codes/requirements.laxed.txt\n",
        "- Change transformers to transformers==4.29.2 (line 39)\n",
        "\n",
        "##### File: codes/utils/util.py\n",
        "- Change to *from torch import inf* (line 25)"
      ],
      "metadata": {
        "id": "nfKOTk4ywqn5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install all required modules and clone repo with altered fine-tuning code"
      ],
      "metadata": {
        "id": "P5LYvd1awqn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/thisserand/DL-Art-School\n",
        "%cd DL-Art-School/codes/\n",
        "!pip install -r requirements.laxed.txt"
      ],
      "metadata": {
        "id": "inq8ZbLSwqn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download model weights for the VQ-VAE and Autoregressive Model (GPT-2)"
      ],
      "metadata": {
        "id": "vViFPS27wqn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/Gatozu35/tortoise-tts/resolve/main/dvae.pth -O ../experiments/dvae.pth\n",
        "!wget https://huggingface.co/jbetker/tortoise-tts-v2/resolve/main/.models/autoregressive.pth -O ../experiments/autoregressive.pth"
      ],
      "metadata": {
        "id": "hYAL4Ma_wqn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create text file containing all transcriptions as source to train a tokenizer"
      ],
      "metadata": {
        "id": "Vs8fJqIiwqn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transcriptions = \"\"\n",
        "dataset_path = \"../../dataset\"\n",
        "\n",
        "for stage in [\"train\", \"val\"]:\n",
        "    with open(f'{dataset_path}/{stage}.txt') as f:\n",
        "        for line in f.readlines():\n",
        "            transcriptions += ' ' + line.split(\"|\")[1].strip()\n",
        "\n",
        "with open(\"transcriptions.txt\", \"w\") as f:\n",
        "  f.write(transcriptions.strip())"
      ],
      "metadata": {
        "id": "X-7qoFmhwqn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Tokenizer"
      ],
      "metadata": {
        "id": "-pa7D3YOwqn6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import torch\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import BPE\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "from tokenizers.trainers import BpeTrainer\n",
        "from german_transliterate.core import GermanTransliterate\n",
        "\n",
        "\n",
        "def text_cleaners(text):\n",
        "  ###########################################\n",
        "  # ToDo Adjust this code for your language #\n",
        "  ###########################################\n",
        "  text = GermanTransliterate().transliterate(text)\n",
        "  text = text.lower()\n",
        "  text = re.sub(re.compile(r'\\s+'), ' ', text)\n",
        "  text = text.replace('\"', '')\n",
        "  return text\n",
        "\n",
        "\n",
        "def remove_extraneous_punctuation(word):\n",
        "    replacement_punctuation = {\n",
        "        '{': '(', '}': ')',\n",
        "        '[': '(', ']': ')',\n",
        "        '`': '\\'', '—': '-',\n",
        "        '—': '-', '`': '\\'',\n",
        "        'ʼ': '\\''\n",
        "    }\n",
        "    replace = re.compile(\"|\".join([re.escape(k) for k in sorted(replacement_punctuation, key=len, reverse=True)]), flags=re.DOTALL)\n",
        "    word = replace.sub(lambda x: replacement_punctuation[x.group(0)], word)\n",
        "    extraneous = re.compile(r'^[@#%_=\\$\\^&\\*\\+\\\\]$')\n",
        "    word = extraneous.sub('', word)\n",
        "    return word\n",
        "\n",
        "with open('transcriptions.txt', 'r', encoding='utf-8') as at:\n",
        "    ttsd = at.readlines()\n",
        "    allowed_characters_re = re.compile(r'^[a-zäöüß!:;\"/, \\-\\(\\)\\.\\'\\?ʼ]+$')\n",
        "\n",
        "    def preprocess_word(word, report=False):\n",
        "        word = text_cleaners(word)\n",
        "        word = remove_extraneous_punctuation(word)\n",
        "        if not bool(allowed_characters_re.match(word)):\n",
        "            if report and word:\n",
        "                print(f\"REPORTING: '{word}'\")\n",
        "            return ''\n",
        "        return word\n",
        "\n",
        "    def batch_iterator(batch_size=1000):\n",
        "        print(\"Processing ASR texts.\")\n",
        "        for i in range(0, len(ttsd), batch_size):\n",
        "            yield [preprocess_word(t, True) for t in ttsd[i:i+batch_size]]\n",
        "\n",
        "    trainer = BpeTrainer(special_tokens=['[STOP]', '[UNK]', '[SPACE]'], vocab_size=255)\n",
        "    tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
        "    tokenizer.pre_tokenizer = Whitespace()\n",
        "    tokenizer.train_from_iterator(batch_iterator(), trainer, length=len(ttsd))\n",
        "    tokenizer.save('../custom_language_tokenizer.json')"
      ],
      "metadata": {
        "id": "qDO0La4Hwqn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import soundfile as sf\n",
        "\n",
        "def resample_wav_file(input_file, target_sampling_rate=22050):\n",
        "    # Load audio file\n",
        "    audio, sampling_rate = librosa.load(input_file, sr=None)\n",
        "\n",
        "    # Check if the sampling rate matches the target\n",
        "    if sampling_rate != target_sampling_rate:\n",
        "\n",
        "        # Resample audio to the target sampling rate\n",
        "        audio_resampled = librosa.resample(audio, orig_sr=sampling_rate, target_sr=target_sampling_rate)\n",
        "\n",
        "        # Overwrite the input file with the resampled audio\n",
        "        sf.write(input_file, audio_resampled, target_sampling_rate)\n",
        "\n",
        "# Resample all audio samples to 22.05kHz\n",
        "dataset_path = \"../../dataset/wavs/\"\n",
        "for wav_file in glob(dataset_path + \"*.wav\"):\n",
        "    resample_wav_file(input_file)"
      ],
      "metadata": {
        "id": "9IFVaZ0xwqn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fine-Tune the Autoregressive Model"
      ],
      "metadata": {
        "id": "PnMHDUGbwqn6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 train.py -opt ../experiments/custom_language_gpt.yml"
      ],
      "metadata": {
        "id": "NB77xOOswqn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RqLFn8t9KVU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import HfApi\n",
        "api = HfApi()\n",
        "\n",
        "hf_user_name = \"\"\n",
        "repository_name = \"\"\n",
        "repo_id = f\"{hf_user_name}/{repository_name}\"\n",
        "fine_tuned_model_path = \"../experiments/custom_language_gpt/models/2500_gpt.pth\"\n",
        "hf_auth_token = \"\"\n",
        "\n",
        "\n",
        "api.create_repo(repo_id=repo_id, token=hf_auth_token, repo_type='model')\n",
        "\n",
        "model_url = api.upload_file(\n",
        "    path_or_fileobj=\"fine_tuned_model_path\",\n",
        "    path_in_repo=\"custom_language_gpt.pth\",\n",
        "    repo_id=repo_id,\n",
        "    repo_type=\"model\",\n",
        ")\n",
        "\n",
        "print(f\"The fine-tuned model was uploaded to: {model_url}\")"
      ],
      "metadata": {
        "id": "W_ujCh4vwqn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clone adjusted inference code for German language"
      ],
      "metadata": {
        "id": "l0R6Q0WSSqKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://gitlab.com/tisserand13/tortoise-tts\n",
        "%cd tortoise-tts\n",
        "!pip install -e ."
      ],
      "metadata": {
        "id": "njGCsV8dSiaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define example text and voice samples to assess generation quality"
      ],
      "metadata": {
        "id": "WMbr13alS0GD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_texts = [\"Das Trainieren von Sprachmodellen für neue Sprachen funktioniert äußerst gut!\",\n",
        "                 \"Äpfel und Birnen sind gesund für den Körper.\",\n",
        "                 \"Übermorgen fahren wir in die Berge.\",\n",
        "                 \"Das Café um die Ecke serviert köstlichen Kuchen und Kaffee.\",\n",
        "                 \"Ein leises Lachen verzaubert die Luft und lässt Herzen höher schlagen.\",\n",
        "                 \"Inmitten des Blütenmeers wandern wir durch den zauberhaften Frühlingswald.\"\n",
        "                ]\n",
        "\n",
        "voices = [\"tom\", \"train_atkins\", \"angie\", \"daniel\", \"deniro\", \"emma\"]"
      ],
      "metadata": {
        "id": "ZIveM1W6S8lD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate speech"
      ],
      "metadata": {
        "id": "b0ICf9aJS-au"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tortoise.api import TextToSpeech\n",
        "from tortoise.utils.audio import load_voice\n",
        "import torchaudio\n",
        "import IPython\n",
        "\n",
        "tts = TextToSpeech(kv_cache=True)\n",
        "\n",
        "for voice, text in zip(voices, example_texts):\n",
        "    voice_samples, _ = load_voice(voice)\n",
        "    audio = tts.tts_with_preset(text, voice_samples=voice_samples, preset='fast')\n",
        "    torchaudio.save(f'{voice}.wav', audio.squeeze(0), 24000)\n",
        "    IPython.display.display(IPython.display.Audio(f'{voice}.wav'))"
      ],
      "metadata": {
        "id": "BreeYZiuTBua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "\n",
        "hop_length = 512\n",
        "db_threshold = -45\n",
        "\n",
        "def trim_audio(audio):\n",
        "    generated_audio = audio.squeeze().numpy()\n",
        "    audio_rms = librosa.feature.rms(y=generated_audio, frame_length=2048, hop_length=hop_length)[0]\n",
        "    audio_db = librosa.power_to_db(rmse**2, ref=np.max)\n",
        "\n",
        "    start_index, end_index = None, None\n",
        "    for index, frame_rms in enumerate(y_values):\n",
        "        if frame_rms >= db_threshold:\n",
        "            if start_index is None:\n",
        "                    start_index = index\n",
        "        elif start_index is not None:\n",
        "            end_index = index - 1\n",
        "            break\n",
        "\n",
        "    return audio.squeeze(0)[:, start_index*hop_length:end_index*hop_length]"
      ],
      "metadata": {
        "id": "9zuqHIlb4mEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimization code"
      ],
      "metadata": {
        "id": "i5Z_u6dYKmHA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.quantization\n",
        "import time\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "import torchaudio\n",
        "from tortoise.api import TextToSpeech\n",
        "from tortoise.utils.audio import load_voice\n",
        "import pandas as pd\n",
        "from typing import List, Tuple, Dict\n",
        "import librosa\n",
        "import pesq\n",
        "from torch.nn.utils import prune\n",
        "\n",
        "class ModelOptimizer:\n",
        "    def __init__(self, model_path: str = None):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.original_model = TextToSpeech(kv_cache=True)\n",
        "        self.quantized_model = None\n",
        "        self.pruned_model = None\n",
        "        self.test_texts = [\n",
        "            \"Das Trainieren von Sprachmodellen für neue Sprachen funktioniert äußerst gut!\",\n",
        "            \"Äpfel und Birnen sind gesund für den Körper.\",\n",
        "            \"Übermorgen fahren wir in die Berge.\"\n",
        "        ]\n",
        "        self.test_voices = [\"tom\", \"angie\", \"daniel\"]\n",
        "\n",
        "    def quantize_model(self) -> None:\n",
        "        \"\"\"\n",
        "        Apply post-training static quantization to the model\n",
        "        \"\"\"\n",
        "        # Configure quantization\n",
        "        self.quantized_model = torch.quantization.quantize_dynamic(\n",
        "            self.original_model,\n",
        "            {torch.nn.Linear, torch.nn.Conv1d, torch.nn.Conv2d},\n",
        "            dtype=torch.qint8\n",
        "        )\n",
        "\n",
        "    def prune_model(self, amount: float = 0.3) -> None:\n",
        "        \"\"\"\n",
        "        Apply weight pruning to reduce model size\n",
        "        Args:\n",
        "            amount: Amount of weights to prune (0.0 to 1.0)\n",
        "        \"\"\"\n",
        "        self.pruned_model = self.original_model\n",
        "        for name, module in self.pruned_model.named_modules():\n",
        "            if isinstance(module, (nn.Conv1d, nn.Conv2d, nn.Linear)):\n",
        "                prune.l1_unstructured(module, name='weight', amount=amount)\n",
        "                prune.remove(module, 'weight')\n",
        "\n",
        "    def measure_inference_time(self, model, num_runs: int = 5) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        Measure inference time statistics\n",
        "        Args:\n",
        "            model: Model to evaluate\n",
        "            num_runs: Number of inference runs to average over\n",
        "        Returns:\n",
        "            Dictionary containing timing statistics\n",
        "        \"\"\"\n",
        "        timing_stats = []\n",
        "\n",
        "        for voice in self.test_voices:\n",
        "            voice_samples, _ = load_voice(voice)\n",
        "\n",
        "            for text in self.test_texts:\n",
        "                for _ in range(num_runs):\n",
        "                    start_time = time.time()\n",
        "                    with torch.no_grad():\n",
        "                        _ = model.tts_with_preset(text, voice_samples=voice_samples, preset='fast')\n",
        "                    end_time = time.time()\n",
        "                    timing_stats.append(end_time - start_time)\n",
        "\n",
        "        return {\n",
        "            \"mean\": np.mean(timing_stats),\n",
        "            \"std\": np.std(timing_stats),\n",
        "            \"min\": np.min(timing_stats),\n",
        "            \"max\": np.max(timing_stats)\n",
        "        }\n",
        "\n",
        "    def evaluate_audio_quality(self, model, reference_model) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        Evaluate audio quality using PESQ score\n",
        "        Args:\n",
        "            model: Model to evaluate\n",
        "            reference_model: Reference model for comparison\n",
        "        Returns:\n",
        "            Dictionary containing quality metrics\n",
        "        \"\"\"\n",
        "        pesq_scores = []\n",
        "\n",
        "        for voice in self.test_voices:\n",
        "            voice_samples, _ = load_voice(voice)\n",
        "\n",
        "            for text in self.test_texts:\n",
        "                # Generate audio with both models\n",
        "                with torch.no_grad():\n",
        "                    reference_audio = reference_model.tts_with_preset(\n",
        "                        text, voice_samples=voice_samples, preset='fast'\n",
        "                    ).squeeze().numpy()\n",
        "                    test_audio = model.tts_with_preset(\n",
        "                        text, voice_samples=voice_samples, preset='fast'\n",
        "                    ).squeeze().numpy()\n",
        "\n",
        "                # Ensure same length for PESQ calculation\n",
        "                min_len = min(len(reference_audio), len(test_audio))\n",
        "                reference_audio = reference_audio[:min_len]\n",
        "                test_audio = test_audio[:min_len]\n",
        "\n",
        "                # Calculate PESQ score\n",
        "                pesq_score = pesq.pesq(24000, reference_audio, test_audio, 'wb')\n",
        "                pesq_scores.append(pesq_score)\n",
        "\n",
        "        return {\n",
        "            \"mean_pesq\": np.mean(pesq_scores),\n",
        "            \"std_pesq\": np.std(pesq_scores)\n",
        "        }\n",
        "\n",
        "    def get_model_size(self, model) -> float:\n",
        "        \"\"\"\n",
        "        Calculate model size in MB\n",
        "        Args:\n",
        "            model: Model to measure\n",
        "        Returns:\n",
        "            Size in MB\n",
        "        \"\"\"\n",
        "        torch.save(model.state_dict(), \"temp_model.pth\")\n",
        "        size_mb = os.path.getsize(\"temp_model.pth\") / (1024 * 1024)\n",
        "        os.remove(\"temp_model.pth\")\n",
        "        return size_mb\n",
        "\n",
        "    def run_benchmarks(self) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Run comprehensive benchmarks on all model variants\n",
        "        Returns:\n",
        "            DataFrame containing benchmark results\n",
        "        \"\"\"\n",
        "        results = []\n",
        "\n",
        "        # Test original model\n",
        "        orig_time = self.measure_inference_time(self.original_model)\n",
        "        orig_size = self.get_model_size(self.original_model)\n",
        "        results.append({\n",
        "            \"model\": \"original\",\n",
        "            \"size_mb\": orig_size,\n",
        "            \"inf_time_mean\": orig_time[\"mean\"],\n",
        "            \"inf_time_std\": orig_time[\"std\"],\n",
        "            \"quality_score\": 1.0  # Reference quality\n",
        "        })\n",
        "\n",
        "        # Test quantized model\n",
        "        if self.quantized_model is not None:\n",
        "            quant_time = self.measure_inference_time(self.quantized_model)\n",
        "            quant_size = self.get_model_size(self.quantized_model)\n",
        "            quant_quality = self.evaluate_audio_quality(self.quantized_model, self.original_model)\n",
        "            results.append({\n",
        "                \"model\": \"quantized\",\n",
        "                \"size_mb\": quant_size,\n",
        "                \"inf_time_mean\": quant_time[\"mean\"],\n",
        "                \"inf_time_std\": quant_time[\"std\"],\n",
        "                \"quality_score\": quant_quality[\"mean_pesq\"]\n",
        "            })\n",
        "\n",
        "        # Test pruned model\n",
        "        if self.pruned_model is not None:\n",
        "            pruned_time = self.measure_inference_time(self.pruned_model)\n",
        "            pruned_size = self.get_model_size(self.pruned_model)\n",
        "            pruned_quality = self.evaluate_audio_quality(self.pruned_model, self.original_model)\n",
        "            results.append({\n",
        "                \"model\": \"pruned\",\n",
        "                \"size_mb\": pruned_size,\n",
        "                \"inf_time_mean\": pruned_time[\"mean\"],\n",
        "                \"inf_time_std\": pruned_time[\"std\"],\n",
        "                \"quality_score\": pruned_quality[\"mean_pesq\"]\n",
        "            })\n",
        "\n",
        "        return pd.DataFrame(results)\n",
        "\n",
        "    def generate_report(self) -> str:\n",
        "        \"\"\"\n",
        "        Generate a detailed optimization report\n",
        "        Returns:\n",
        "            Formatted report string\n",
        "        \"\"\"\n",
        "        results_df = self.run_benchmarks()\n",
        "\n",
        "        report = \"TTS Model Optimization Report\\n\"\n",
        "        report += \"==========================\\n\\n\"\n",
        "\n",
        "        # Model Size Comparison\n",
        "        report += \"Model Size Comparison:\\n\"\n",
        "        report += f\"Original Model: {results_df.loc[results_df['model'] == 'original', 'size_mb'].values[0]:.2f} MB\\n\"\n",
        "        if self.quantized_model is not None:\n",
        "            quant_size = results_df.loc[results_df['model'] == 'quantized', 'size_mb'].values[0]\n",
        "            reduction = (1 - quant_size / results_df.loc[results_df['model'] == 'original', 'size_mb'].values[0]) * 100\n",
        "            report += f\"Quantized Model: {quant_size:.2f} MB ({reduction:.1f}% reduction)\\n\"\n",
        "        if self.pruned_model is not None:\n",
        "            pruned_size = results_df.loc[results_df['model'] == 'pruned', 'size_mb'].values[0]\n",
        "            reduction = (1 - pruned_size / results_df.loc[results_df['model'] == 'original', 'size_mb'].values[0]) * 100\n",
        "            report += f\"Pruned Model: {pruned_size:.2f} MB ({reduction:.1f}% reduction)\\n\"\n",
        "\n",
        "        # Inference Time Comparison\n",
        "        report += \"\\nInference Time Comparison:\\n\"\n",
        "        for _, row in results_df.iterrows():\n",
        "            report += f\"{row['model'].capitalize()} Model: {row['inf_time_mean']:.3f}s ± {row['inf_time_std']:.3f}s\\n\"\n",
        "\n",
        "        # Quality Comparison\n",
        "        report += \"\\nQuality Metrics (PESQ Score):\\n\"\n",
        "        for _, row in results_df.iterrows():\n",
        "            report += f\"{row['model'].capitalize()} Model: {row['quality_score']:.3f}\\n\"\n",
        "\n",
        "        return report\n",
        "\n",
        "def main():\n",
        "    # Initialize optimizer\n",
        "    optimizer = ModelOptimizer()\n",
        "\n",
        "    # Apply optimizations\n",
        "    optimizer.quantize_model()\n",
        "    optimizer.prune_model(amount=0.3)\n",
        "\n",
        "    # Generate and print report\n",
        "    report = optimizer.generate_report()\n",
        "    print(report)\n",
        "\n",
        "    # Save report to file\n",
        "    with open(\"optimization_report.txt\", \"w\") as f:\n",
        "        f.write(report)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "Su_32GqmKi9W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}